n_runs: 4
n_threads: 10
map_image: empty_4x4
map_size: [4, 4]
robot_diam: 0.7
buffer_length: 10000
batch_size: 1000
n_episodes: 2000
n_agents: 2
episode_length: 60
steps_per_update: 1
save_interval: 100
eval_interval: 50
actor_hidden_dim: 64
critic_hidden_dim: 64
seed: 0
tau: 0.99
gamma: 0.95
auto_entropy: true
min_linear_speed: 0.
max_linear_speed: 1.
max_angular_speed: 1.
goal_reaching_reward: 1.
goal_distance_reward_mult: -0.0
collision_reward_start: 0.
collision_reward_end: -1.0
collision_reward_decay_ep_start: 0
collision_reward_decay_ep_end: 1000
device: cpu
